---
title: "Naming_and_filtering"
author: "Aurora"
date: "`r Sys.Date()`"
output: html_document
---


```{r Libraries, warning=FALSE, message=FALSE, echo=FALSE}
## you need to download these packages
library(stringr) # needed to extract values from strings: str_extract(row.names(A1), "(f[0-9]+_r[0-9]+)"
library(Biostrings)
library(dplyr) #if tidyverse is needed drop this
library(vegan) #NMDS: calculating distances between samples
library(MASS)
library(ggalt)
library(caret) # machine learning
library(randomForest) # machine learning
library(reshape2)
library(rstudioapi) # setting working directory



#library(tidyverse)
#library(ranger)
#library(plotrix)
#library(forcats)
#library(tidyr)
#library(patchwork)
#library(knitr)

#these are loaded in contamination script
library(ggplot2) # plotting
library(phyloseq) # handling microbiome data
library(decontam) # for finding contaminants
```

```{r setting_WD_to_source_file_location}
setwd(dirname(getActiveDocumentContext()$path)) #setting Working directory
print(getwd()) # Checking working directory
```


```{r file_paths_all_samples_in_dada2_aurora}
### dada2 files from run with A1 samples
tab_file="dada2_tab.txt" #ASV output from dada2 for fall samples
tax_file="dada2_taxonomy.txt" #taxonomic output from dada2 for fall samples
ASV_seq_file="ASV.fas" #ASV sequence output from dada2 for fall samples

### platemap files (position on plate of each sample)
platemap_file="platemap.txt" #information about which primers are in which well in the plate
pmA1_file="A1_pm.txt" #placement of samples on A1 plate (UIO lab, fall)
pmA2_file="A2_pm.txt" #placement of samples on A2 plate (OUS lab, fall)
pmpilot_file="pm_pilot.txt"#placement of samples on A1 plate (UIO lab, summer)

### output paths/files
file_out ="tab.txt"
tax_file_out ="taxonomy_filtered.txt"
ctr_file_out = "control_samples_ASV_table.txt"
ctr_tax_file_out ="control_samples_tax_table.txt"
ctrl_andSamples_file_out= "control_with_samples_ASV_table.txt"
ctrl_andSamples_tax_file_out= "control_with_samples_tax_table.txt"
asv_file_out = "sequences_filtered.txt"
metaData_file_out = "metaData.txt"
OTU_file_out = "OTU_tab.txt"

```



```{r filtering_options}
reads_low_limit = 3000 #cutoff for samples to include in analysis
min_asv_length = 245 #lower cutoff read length
max_asv_length = 263 #higher cutoff read length
singletons = 4 #remove ASVs with less total reads than this
```

```{r load_dada2_tbl_alle_prøver_kjørt_sammen}
tab_dadaEirik <-read.table(tab_file, row.names=1,header=T) #load table file
dim(tab_dadaEirik) # Check dimensions
```

#assigning names

```{r loading_files_needed_for_naming}
platemap <- read.table(platemap_file) # Shows which primers were used in which well of the plate
# making the platemap into a vector with the entries in a specific order
platemap_vect <- as.data.frame(as.vector(as.matrix(platemap)))

pmA1<-read.table(pmA1_file,header=T,row.names=1) # In which well each plate was loaded
pmA1_vect <- as.data.frame(as.vector(as.matrix(pmA1)))
  
pmA2<-read.table(pmA2_file,header=T,row.names=1) # In which well each plate was loaded
pmA2_vect <- as.data.frame(as.vector(as.matrix(pmA2)))

pmpilot<-read.table(pmpilot_file,header=T,row.names=1) # In which well each plate was loaded
pmpilot_vect <- as.data.frame(as.vector(as.matrix(pmpilot)))
```

```{r assigning_names_dada2_with_all_samples}
Pilot <- subset(tab_dadaEirik, (grepl("P1_", rownames(tab_dadaEirik))))
A1 <- subset(tab_dadaEirik, (grepl("A1_", rownames(tab_dadaEirik))))
A2 <- subset(tab_dadaEirik, (grepl("A2_", rownames(tab_dadaEirik))))

#Setting samplenames for A1 by matching primers used with sample names based on position on plate
combA1_tbl <- as.data.frame(cbind(pmA1_vect, platemap_vect)) 
colnames(combA1_tbl) <- c("id", "map_pos")
A1$rownames_col <- str_extract(row.names(A1), "(f[0-9]+_r[0-9]+)")
mergedA1_table <- merge(A1, combA1_tbl, by.x = "rownames_col", by.y = "map_pos")
rownames(mergedA1_table) <- mergedA1_table$id
A1 <- subset(mergedA1_table, select= -c(rownames_col, id))
print(row.names(A1))

#Setting samplenames for A2 by matching primers used with sample names based on position on plate
combA2_tbl <- as.data.frame(cbind(pmA2_vect, platemap_vect)) # data frame where each row is a well on the plate and the 2 columns say which primers were used for that well and the sample that was placed there
colnames(combA2_tbl) <- c("id", "map_pos") 
A2$rownames_col <- str_extract(row.names(A2), "(f[0-9]+_r[0-9]+)") # extracting the primer information (combination of forward and reverse used) from the output sample name (from demultiplexing)
mergedA2_table <- merge(A2, combA2_tbl, by.x = "rownames_col", by.y = "map_pos") # merging the two tables based on primer information
rownames(mergedA2_table) <- mergedA2_table$id # Set sample name (id) as row names
A2 <- subset(mergedA2_table, select= -c(rownames_col, id))
print(row.names(A2))

#Setting sample names for pilot by matching primers used with sample names based on position on plate
combPilot_tbl <- as.data.frame(cbind(pmpilot_vect, platemap_vect)) 
colnames(combPilot_tbl) <- c("id", "map_pos")
Pilot$rownames_col <- str_extract(row.names(Pilot), "(f[0-9]+_r[0-9]+)")
mergedPilot_table <- merge(Pilot, combPilot_tbl, by.x = "rownames_col", by.y = "map_pos")
rownames(mergedPilot_table) <- paste0(mergedPilot_table$id, "_P")
Pilot <- subset(mergedPilot_table, select= -c(rownames_col, id))
print(row.names(Pilot))

#combine the tables again
tab <- rbind(Pilot, A1) # Not including A2 here because method is not the focus
```

```{r remove_samples_not_included_in_project}
rows_to_remove <- c(paste0("ER", 1:10),"Evapoo1", "Evapoo2") #chose samples not wanted in the analysis (from the sequencing run, but not soil samples)
tab <- tab[!rownames(tab) %in% rows_to_remove, ] #Remove chosen samples
dim(tab)
print(row.names(tab))

keep<-colSums(tab)>0 
table(keep)
tab <-tab[,keep]
dim(tab)
```

```{r load_tax_file}
tax <-read.table(tax_file, header=T)#load taxa file
dim(tax)
tax <- tax[keep,]
dim(tax)
row.names(tax) <- colnames(tab)
```

# Filtering

```{r remove_ASV_with_wrong_lenght}
asv <- as.data.frame(readDNAStringSet(ASV_seq_file)) # load the file containing the ASV list and their corresponding sequences
dim(asv)
sum(nchar(asv$x) < min_asv_length) 
asv <- asv[nchar(asv$x) >= min_asv_length, , drop = FALSE]
dim(asv)
sum(nchar(asv$x) > max_asv_length)
asv <- asv[nchar(asv$x) <= max_asv_length, , drop = FALSE]
dim(asv)

# checking that the filtering is correct
seq_length <- nchar(asv$x)
hist(seq_length) 
print(table(seq_length))

#remove from ASV table
keep_ASV_cor_lenght <- intersect(row.names(asv), colnames(tab))
tab <- tab[, colnames(tab) %in% keep_ASV_cor_lenght, drop = FALSE]
dim(tab)

#remove from tax table
tax <- tax[row.names(tax) %in% keep_ASV_cor_lenght,]
dim(tax)
identical(colnames(tab), row.names(tax)) # check that they are identical
```

```{r remove_ASVs_that_cannot_be_assigned_at_phylum_level}
tab <-tab[,-which(is.na(tax[,2]))]
dim(tab)
tax <- tax[!is.na(tax[,2]),]
dim(tax)
```
```{r remove_singletons}
keep<-colSums(tab)>singletons 
table(keep)
tab <-tab[,keep]
dim(tab)
tax <- tax[keep, ]
dim(tax)
```
```{r order_ASV_table}
idx <- order(row.names(tab))
tab <- tab[idx,]
head(rownames(tab))
```




```{r metadata}
#Creating Metadata from samplenames

sample_type <- character(length(row.names(tab)))
for (i in 1:length(row.names(tab))) {
if (substring(row.names(tab)[i], 3, 3) == 'F' | substring(row.names(tab)[i], 2, 2) == '4') {
  sample_type[i]<-"fabric"
} else {
  sample_type[i]<-"soil"
}
}

place <- substring(row.names(tab),1,1)
timestamp <- substring(row.names(tab),2,2)
idx <- grep("_P",row.names(tab))
timestamp[idx] <- "P"
idx <- grep("1",timestamp)
timestamp[idx] <- "14"
ctrl <-  grepl("Nctr", substring(row.names(tab), 1, 4)) | grepl("sneg", row.names(tab))
batch <- grepl("_P", row.names(tab))

metaData <- as.data.frame(cbind(place,timestamp,sample_type, ctrl, batch))
row.names(metaData) <- row.names(tab)

metaData$place[metaData$ctrl == TRUE] <- "neg_ctrl"
metaData$ctrl <- as.logical(metaData$ctrl)

```

```{r contamination}
source("contamination.R") 
```

output from contamination.Rmd is phyloseq object ps_clean and tables: tab, tax, metaData (all with ASVs identified as contaminants removed)

```{r Remove_all_samples_with_<X_reads}
sum(rowSums(tab)<reads_low_limit)
rowSums(tab)[which(rowSums(tab)<reads_low_limit)]
tab<-tab[rowSums(tab)>=reads_low_limit,]
dim(tab)
metaData <- (metaData[row.names(metaData) %in% row.names(tab), , drop = FALSE])


```

```{r removing_control_samples_and_0abundance_ASVs}
metaData <- metaData[! metaData$place == "neg_ctrl", ]
metaData <- metaData %>%
  mutate(Season = ifelse(batch == TRUE, "summer", "fall"))
metaData <-  dplyr::select(metaData, c("place", "timestamp","sample_type", "Season"))
tab <- (tab[row.names(tab) %in% row.names(metaData), , drop = FALSE])

#remove ASVs not found in Asv table (prevalence 0)
keep<-colSums(tab)>0 
table(keep) # where is the 117 ASVS from? (are they not contaminants because they are only present in controll samples not in actual samples?)
tab <-tab[,keep] 
tax <-tax[keep,]
```

```{r filtering_sequence_table}
asv <- (asv[row.names(asv) %in% colnames(tab), , drop = FALSE])
dim(asv)
```



# Saving files for analysis

```{r save_filtered_tbl}
dim(asv)
dim(tax)
dim(tab)
dim(metaData)
write.table(tab, file_out, sep = "\t")
write.table(tax, tax_file_out, sep = "\t")
write.table(asv, asv_file_out, sep = "\t")
write.table(metaData, metaData_file_out, sep = "\t")
```