---
title: "Naming_and_filtering"
author: ""
date: "`r Sys.Date()`"
output: html_document
---


```{r Libraries, warning=FALSE, message=FALSE, echo=FALSE}
## you need to download these packages
library(rstudioapi) # setting working directory
library(stringr) # needed to extract values from strings: str_extract(row.names(A1), "(f[0-9]+_r[0-9]+)"
library(Biostrings) # ReadDNAStringSet
library(dplyr) #
library(phyloseq) # handling microbiome data
library(vegan)
```

```{r setting_WD_to_source_file_location}
setwd(dirname(getActiveDocumentContext()$path)) #setting Working directory
print(getwd()) 
```


```{r file_paths}
### output from dada2 
tab_file="dada2_tab.txt" #ASV abundance output from dada2 
tax_file="dada2_taxonomy.txt" #taxonomic output from dada2 
ASV_seq_file="ASV.fas" #ASV sequence output from dada2 

### platemap files (position on plate of each sample used for assigning names)
platemap_file="platemap.txt" #information about which primers are in which well in the plate
pmA1_file="A1_pm.txt" #placement of samples on A1 plate (fall) 
pmpilot_file="pm_pilot.txt"#placement of samples on summer plate (summer)

### output paths/files
file_out ="tab.txt"
tax_file_out ="taxonomy_filtered.txt"
asv_file_out = "sequences_filtered.txt"
metaData_file_out = "metaData.txt"

```


```{r filtering_options}
reads_low_limit = 3000 #cutoff for samples to include in analysis
min_asv_length = 245 #lower cutoff read length
max_asv_length = 263 #higher cutoff read length
singletons = 4 #remove ASVs with less total reads than this
```

```{r load_dada2_tbl}
tab_dada <-read.table(tab_file, row.names=1,header=T) #load table file
dim(tab_dada) # Check dimensions
```

#assigning names

```{r loading_files_needed_for_naming}
platemap <- read.table(platemap_file) # Shows which primers were used in which well of the plate
# making the platemap into a vector with the entries in a specific order
platemap_vect <- as.data.frame(as.vector(as.matrix(platemap)))

pmA1<-read.table(pmA1_file,header=T,row.names=1) # In which well each fall sample was loaded
pmA1_vect <- as.data.frame(as.vector(as.matrix(pmA1)))
  
pmpilot<-read.table(pmpilot_file,header=T,row.names=1) # In which well each summer sample was loaded
pmpilot_vect <- as.data.frame(as.vector(as.matrix(pmpilot)))
```

```{r assigning_names}
# separating the samples by sequencing plates
Pilot <- subset(tab_dada, (grepl("P1_", rownames(tab_dada)))) # summer data
A1 <- subset(tab_dada, (grepl("A1_", rownames(tab_dada)))) # fall data

#Setting samplenames for A1 by matching primers used with sample names based on position on plate
combA1_tbl <- as.data.frame(cbind(pmA1_vect, platemap_vect))  
colnames(combA1_tbl) <- c("id", "map_pos")
A1$rownames_col <- str_extract(row.names(A1), "(f[0-9]+_r[0-9]+)")
mergedA1_table <- merge(A1, combA1_tbl, by.x = "rownames_col", by.y = "map_pos")
rownames(mergedA1_table) <- mergedA1_table$id
A1 <- subset(mergedA1_table, select= -c(rownames_col, id))
print(row.names(A1))


#Setting sample names for pilot by matching primers used with sample names based on position on plate
combPilot_tbl <- as.data.frame(cbind(pmpilot_vect, platemap_vect)) 
colnames(combPilot_tbl) <- c("id", "map_pos")
Pilot$rownames_col <- str_extract(row.names(Pilot), "(f[0-9]+_r[0-9]+)")
mergedPilot_table <- merge(Pilot, combPilot_tbl, by.x = "rownames_col", by.y = "map_pos")
rownames(mergedPilot_table) <- paste0(mergedPilot_table$id, "_P")
Pilot <- subset(mergedPilot_table, select= -c(rownames_col, id))
print(row.names(Pilot))

#combine the tables again
tab <- rbind(Pilot, A1) 
```

```{r positive_controls}
rows_to_remove <- c("Evapoo1", "Evapoo2") # positive controls
pos_ctr <- tab[rownames(tab) %in% rows_to_remove, ]
pos_ctr_dist <-as.matrix(vegdist(pos_ctr, method = "bray")) 

tab <- tab[!rownames(tab) %in% rows_to_remove, ] #Remove positive controls
dim(tab)
print(row.names(tab))

# Remove ASVs with 0 abundance in filtered dataset
keep<-colSums(tab)>0 
table(keep)
tab <-tab[,keep]
dim(tab)

# make sure the tax file matches the ASV file
tax <-read.table(tax_file, header=T)#load taxa file
dim(tax)
tax <- tax[keep,]
dim(tax)
row.names(tax) <- colnames(tab)
```


# Filtering

```{r remove_ASV_with_wrong_lenght}
asv <- as.data.frame(readDNAStringSet(ASV_seq_file)) # load the file containing the ASV list and their corresponding sequences
dim(asv)
sum(nchar(asv$x) < min_asv_length) # check nr of ASVs with shorter sequence than the cut off
asv <- asv[nchar(asv$x) >= min_asv_length, , drop = FALSE]
dim(asv)
sum(nchar(asv$x) > max_asv_length) # check nr of ASVs longer than cut off
asv <- asv[nchar(asv$x) <= max_asv_length, , drop = FALSE]
dim(asv)

# checking that the filtering is correct
seq_length <- nchar(asv$x)
hist(seq_length) 

#remove from ASV table
keep_ASV_cor_lenght <- intersect(row.names(asv), colnames(tab))
tab <- tab[, colnames(tab) %in% keep_ASV_cor_lenght, drop = FALSE]
dim(tab)

#remove from tax table
tax <- tax[row.names(tax) %in% keep_ASV_cor_lenght,]
dim(tax)
identical(colnames(tab), row.names(tax)) # check that they are identical
```

```{r remove_ASVs_that_cannot_be_assigned_at_phylum_level}
tab <-tab[,-which(is.na(tax[,2]))]
dim(tab)
tax <- tax[!is.na(tax[,2]),]
dim(tax)
```

```{r remove_singletons}
#removing ASVs with less reads than the cut off value
keep<-colSums(tab)>singletons 
table(keep)
tab <-tab[,keep]
dim(tab)
tax <- tax[keep, ]
dim(tax)
```

```{r order_ASV_table}
idx <- order(row.names(tab))
tab <- tab[idx,]
head(rownames(tab))
```


```{r metadata}
#Creating Metadata from samplenames
#Type of sample (soil or fabric)
sample_type <- character(length(row.names(tab)))
for (i in 1:length(row.names(tab))) {
if (substring(row.names(tab)[i], 3, 3) == 'F' | substring(row.names(tab)[i], 2, 2) == '4') {
  sample_type[i]<-"fabric"
} else {
  sample_type[i]<-"soil"
}
}
#sampling location
place <- substring(row.names(tab),1,1)
#sampling day for fall samples and season for summer samples
timestamp <- substring(row.names(tab),2,2)
idx <- grep("_P",row.names(tab))
timestamp[idx] <- "P"
idx <- grep("1",timestamp)
timestamp[idx] <- "14"
#mark negative control samples
ctrl <-  grepl("Nctr", substring(row.names(tab), 1, 4)) | grepl("sneg", row.names(tab))
# sort samples based on lab run
batch <- grepl("_P", row.names(tab))

metaData <- as.data.frame(cbind(place,timestamp,sample_type, ctrl, batch))
row.names(metaData) <- row.names(tab)

metaData$place[metaData$ctrl == TRUE] <- "neg_ctrl"
metaData$ctrl <- as.logical(metaData$ctrl)

```

```{r contamination}
# Script that uses the decontam package to identify contaminants 
source("contamination.R") 
```

output from contamination.Rmd is phyloseq object ps_clean and tables: tab, tax, metaData (all with ASVs identified as contaminants removed)

```{r Remove_all_samples_with_<X_reads}
sum(rowSums(tab)<reads_low_limit)
rowSums(tab)[which(rowSums(tab)<reads_low_limit)]
tab<-tab[rowSums(tab)>=reads_low_limit,]
dim(tab)
metaData <- (metaData[row.names(metaData) %in% row.names(tab), , drop = FALSE])
```

```{r removing_control_samples_and_0abundance_ASVs}
#remove negative control samples
metaData <- metaData[! metaData$place == "neg_ctrl", ]
tab <- (tab[row.names(tab) %in% row.names(metaData), , drop = FALSE])

#change batch to season as that is more informative for analyses
metaData <- metaData %>%
  mutate(Season = ifelse(batch == TRUE, "summer", "fall"))
metaData <-  dplyr::select(metaData, c("place", "timestamp","sample_type", "Season"))


#remove ASVs not found in Asv table (prevalence 0)
keep<-colSums(tab)>0 
table(keep) 
tab <-tab[,keep] 
tax <-tax[keep,]
```

```{r filtering_sequence_table}
# making sure the sequence table contains only the filtered ASVs
asv <- (asv[row.names(asv) %in% colnames(tab), , drop = FALSE])
dim(asv)
```



# Saving files for analysis

```{r save_filtered_tbl}
dim(asv)
dim(tax)
dim(tab)
dim(metaData)
tab[] <- lapply(tab, as.numeric)
write.table(tab, file_out, sep = "\t")
write.table(tax, tax_file_out, sep = "\t")
write.table(asv, asv_file_out, sep = "\t")
write.table(metaData, metaData_file_out, sep = "\t")
```

```{r}
sessionInfo()
```

